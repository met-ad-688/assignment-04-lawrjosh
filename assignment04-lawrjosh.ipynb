{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 04\n",
        "author:\n",
        "  - name: Joshua Lawrence\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2025-10-08'\n",
        "date-modified: today\n",
        "date-format: long\n",
        "format:\n",
        "  html:\n",
        "    theme: sandstone\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "  docx: default\n",
        "execute:\n",
        "  echo: true\n",
        "  eval: true\n",
        "  freeze: auto\n",
        "---\n",
        "\n",
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "pio.renderers.default = \"notebook+notebook_connected+vscode\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "# df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define features and target variable\n",
        "continuous_features = ['MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'SALARY_FROM', 'SALARY_TO']\n",
        "categorical_features = ['REMOTE_TYPE_NAME', 'EMPLOYMENT_TYPE_NAME']\n",
        "target_variable = 'SALARY'\n",
        "\n",
        "# Select columns and drop missing values\n",
        "selected_columns = continuous_features + categorical_features + [target_variable]\n",
        "df_cleaned = df.select(*selected_columns).na.drop()\n",
        "\n",
        "# Create StringIndexers for categorical variables\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col_name, outputCol=col_name + \"_index\", handleInvalid=\"keep\")\n",
        "    for col_name in categorical_features\n",
        "]\n",
        "\n",
        "# Create OneHotEncoders for indexed categorical variables\n",
        "encoders = [\n",
        "    OneHotEncoder(inputCol=col_name + \"_index\", outputCol=col_name + \"_encoded\")\n",
        "    for col_name in categorical_features\n",
        "]\n",
        "\n",
        "# Prepare feature column names\n",
        "encoded_categorical_cols = [col_name + \"_encoded\" for col_name in categorical_features]\n",
        "feature_cols = continuous_features + encoded_categorical_cols\n",
        "\n",
        "# Create VectorAssembler for linear features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "# Build pipeline\n",
        "pipeline_stages = indexers + encoders + [assembler]\n",
        "pipeline = Pipeline(stages=pipeline_stages)\n",
        "\n",
        "# Fit and transform data\n",
        "df_transformed = pipeline.fit(df_cleaned).transform(df_cleaned)\n",
        "\n",
        "# Create polynomial feature: MIN_YEARS_EXPERIENCE_SQ\n",
        "df_poly = df_transformed.withColumn(\n",
        "    \"MIN_YEARS_EXPERIENCE_SQ\", \n",
        "    col(\"MIN_YEARS_EXPERIENCE\") * col(\"MIN_YEARS_EXPERIENCE\")\n",
        ")\n",
        "\n",
        "# Create VectorAssembler for polynomial features\n",
        "poly_feature_cols = continuous_features + [\"MIN_YEARS_EXPERIENCE_SQ\"] + encoded_categorical_cols\n",
        "assembler_poly = VectorAssembler(\n",
        "    inputCols=poly_feature_cols,\n",
        "    outputCol=\"features_poly\",\n",
        "    handleInvalid=\"skip\"\n",
        ")\n",
        "\n",
        "# Transform data with polynomial features\n",
        "df_final = assembler_poly.transform(df_poly)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split data into training and testing sets (80/20 split)\n",
        "train_final, test_final = df_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Get counts\n",
        "train_count = train_final.count()\n",
        "test_count = test_final.count()\n",
        "total_count = df_final.count()\n",
        "\n",
        "print(f\"Total observations: {total_count}\")\n",
        "print(f\"Training set: {train_count} ({train_count/total_count*100:.1f}%)\")\n",
        "print(f\"Testing set: {test_count} ({test_count/total_count*100:.1f}%)\")\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nTraining Data Sample:\")\n",
        "train_final.select(\"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \"SALARY_FROM\", \"SALARY_TO\", \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\").show(5)\n",
        "\n",
        "print(\"\\nTest Data Sample:\")\n",
        "test_final.select(\"SALARY\", \"MIN_YEARS_EXPERIENCE\", \"MAX_YEARS_EXPERIENCE\", \"SALARY_FROM\", \"SALARY_TO\", \"REMOTE_TYPE_NAME\", \"EMPLOYMENT_TYPE_NAME\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize Linear Regression model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"SALARY\", maxIter=100, regParam=0.1, elasticNetParam=0.0)\n",
        "\n",
        "# Train the model\n",
        "lr_model = lr.fit(train_final)\n",
        "\n",
        "# Generate predictions\n",
        "train_predictions = lr_model.transform(train_final)\n",
        "test_predictions = lr_model.transform(test_final)\n",
        "\n",
        "# Initialize evaluators\n",
        "evaluator_r2 = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "evaluator_rmse = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "evaluator_mae = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"mae\")\n",
        "\n",
        "# Evaluate on training set\n",
        "train_r2 = evaluator_r2.evaluate(train_predictions)\n",
        "train_rmse = evaluator_rmse.evaluate(train_predictions)\n",
        "train_mae = evaluator_mae.evaluate(train_predictions)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_r2 = evaluator_r2.evaluate(test_predictions)\n",
        "test_rmse = evaluator_rmse.evaluate(test_predictions)\n",
        "test_mae = evaluator_mae.evaluate(test_predictions)\n",
        "\n",
        "# Extract model parameters\n",
        "coefficients = lr_model.coefficients\n",
        "intercept = lr_model.intercept\n",
        "summary = lr_model.summary\n",
        "\n",
        "# Prepare feature names\n",
        "feature_names = continuous_features + encoded_categorical_cols\n",
        "\n",
        "# Extract coefficient statistics\n",
        "try:\n",
        "    coef_std_errors = summary.coefficientStandardErrors\n",
        "    t_values = summary.tValues\n",
        "    p_values = summary.pValues\n",
        "    \n",
        "    coef_data = []\n",
        "    for i, feature_name in enumerate(feature_names):\n",
        "        if i < len(coefficients):\n",
        "            coef = coefficients[i]\n",
        "            std_err = coef_std_errors[i]\n",
        "            t_val = t_values[i]\n",
        "            p_val = p_values[i]\n",
        "            ci_lower = coef - 1.96 * std_err\n",
        "            ci_upper = coef + 1.96 * std_err\n",
        "            \n",
        "            coef_data.append({\n",
        "                'Feature': feature_name,\n",
        "                'Coefficient': coef,\n",
        "                'Std_Error': std_err,\n",
        "                'T_Value': t_val,\n",
        "                'P_Value': p_val,\n",
        "                'CI_Lower': ci_lower,\n",
        "                'CI_Upper': ci_upper\n",
        "            })\n",
        "    \n",
        "    coef_df = pd.DataFrame(coef_data)\n",
        "    \n",
        "    intercept_std_err = coef_std_errors[-1]\n",
        "    intercept_t_val = t_values[-1]\n",
        "    intercept_p_val = p_values[-1]\n",
        "    intercept_ci_lower = intercept - 1.96 * intercept_std_err\n",
        "    intercept_ci_upper = intercept + 1.96 * intercept_std_err\n",
        "    \n",
        "except:\n",
        "    coef_data = []\n",
        "    for i, feature_name in enumerate(feature_names):\n",
        "        if i < len(coefficients):\n",
        "            coef = coefficients[i]\n",
        "            \n",
        "            coef_data.append({\n",
        "                'Feature': feature_name,\n",
        "                'Coefficient': coef,\n",
        "                'Std_Error': 'N/A',\n",
        "                'T_Value': 'N/A',\n",
        "                'P_Value': 'N/A',\n",
        "                'CI_Lower': 'N/A',\n",
        "                'CI_Upper': 'N/A'\n",
        "            })\n",
        "    \n",
        "    coef_df = pd.DataFrame(coef_data)\n",
        "    \n",
        "    intercept_std_err = 'N/A'\n",
        "    intercept_t_val = 'N/A'\n",
        "    intercept_p_val = 'N/A'\n",
        "    intercept_ci_lower = 'N/A'\n",
        "    intercept_ci_upper = 'N/A'\n",
        "\n",
        "# Print results\n",
        "print(\"=\" * 80)\n",
        "print(\"LINEAR REGRESSION MODEL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "print(f\"Intercept: {intercept:,.2f}\")\n",
        "print(f\"\\nTraining Set Performance:\")\n",
        "print(f\"  R² Score: {train_r2:.4f}\")\n",
        "print(f\"  RMSE: ${train_rmse:,.2f}\")\n",
        "print(f\"  MAE: ${train_mae:,.2f}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"  R² Score: {test_r2:.4f}\")\n",
        "print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
        "print(f\"  MAE: ${test_mae:,.2f}\")\n",
        "\n",
        "print(\"\\n--- Feature Coefficients and Statistical Significance ---\")\n",
        "print(coef_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Intercept Statistics ---\")\n",
        "print(f\"Intercept: {intercept:,.2f}\")\n",
        "print(f\"Std Error: {intercept_std_err}\")\n",
        "print(f\"T-Value: {intercept_t_val}\")\n",
        "print(f\"P-Value: {intercept_p_val}\")\n",
        "print(f\"95% CI: [{intercept_ci_lower}, {intercept_ci_upper}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INTERPRETATION OF RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. MODEL PERFORMANCE INTERPRETATION:\")\n",
        "print(f\"   - R² Score ({test_r2:.4f}): Indicates that {test_r2*100:.2f}% of the variance in SALARY\")\n",
        "print(\"     is explained by the model. A higher R² suggests a better model fit.\")\n",
        "print(f\"   - RMSE (${test_rmse:,.2f}): On average, predictions deviate by ${test_rmse:,.2f} from\")\n",
        "print(\"     actual salaries. Lower RMSE indicates better prediction accuracy.\")\n",
        "print(f\"   - MAE (${test_mae:,.2f}): The average absolute error is ${test_mae:,.2f}.\")\n",
        "print(\"     This is more interpretable and less sensitive to outliers than RMSE.\")\n",
        "\n",
        "print(\"\\n2. COEFFICIENT INTERPRETATION:\")\n",
        "print(\"   - Each coefficient represents the change in SALARY for a one-unit increase\")\n",
        "print(\"     in that feature, holding all other features constant.\")\n",
        "print(\"   - Continuous features (MIN_YEARS_EXPERIENCE, MAX_YEARS_EXPERIENCE, SALARY_FROM, SALARY_TO):\")\n",
        "print(\"     * Positive coefficients: Higher values increase predicted salary\")\n",
        "print(\"     * Negative coefficients: Higher values decrease predicted salary\")\n",
        "print(\"   - Encoded categorical features (REMOTE_TYPE_NAME, EMPLOYMENT_TYPE_NAME):\")\n",
        "print(\"     * Each encoded category represents a binary indicator (0 or 1)\")\n",
        "print(\"     * Positive coefficients: That category increases salary vs. baseline\")\n",
        "print(\"     * Negative coefficients: That category decreases salary vs. baseline\")\n",
        "\n",
        "print(\"\\n3. STATISTICAL SIGNIFICANCE:\")\n",
        "print(\"   - P-Value < 0.05: Feature is statistically significant (reject null hypothesis)\")\n",
        "print(\"   - P-Value > 0.05: Feature may not be statistically significant\")\n",
        "print(\"   - T-Value: Larger absolute values indicate stronger evidence against null hypothesis\")\n",
        "print(\"   - 95% Confidence Interval: If it doesn't contain 0, the feature is significant\")\n",
        "\n",
        "significant_features = coef_df[pd.to_numeric(coef_df['P_Value'], errors='coerce') < 0.05]\n",
        "print(f\"\\n   Statistically significant features (p < 0.05): {len(significant_features)}/{len(coef_df)}\")\n",
        "\n",
        "print(\"\\n4. KEY INSIGHTS:\")\n",
        "print(\"   - MULTICOLLINEARITY ISSUE: SALARY_FROM and SALARY_TO essentially contain\")\n",
        "print(\"     the information we're trying to predict (SALARY). This is called data leakage.\")\n",
        "print(\"   - In a real-world scenario, these features would not be available at prediction time.\")\n",
        "print(\"   - This explains the high R² but also why statistical inference is problematic.\")\n",
        "print(\"   - RECOMMENDATION: Remove SALARY_FROM and SALARY_TO, or create derived features\")\n",
        "print(\"     like salary_range = SALARY_TO - SALARY_FROM for more realistic modeling.\")\n",
        "\n",
        "print(\"\\n5. FEATURE IMPORTANCE (by absolute coefficient value):\")\n",
        "coef_abs = coef_df.copy()\n",
        "if coef_abs['Coefficient'].dtype in ['float64', 'int64']:\n",
        "    coef_abs['Abs_Coefficient'] = abs(coef_abs['Coefficient'])\n",
        "    coef_abs_sorted = coef_abs.sort_values('Abs_Coefficient', ascending=False)\n",
        "    print(coef_abs_sorted[['Feature', 'Coefficient', 'Abs_Coefficient']].head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "# Show sample predictions\n",
        "test_predictions.select(\"SALARY\", \"prediction\", \"features\").show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Polynomial Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize Polynomial Regression model\n",
        "lr_poly = LinearRegression(featuresCol=\"features_poly\", labelCol=\"SALARY\", maxIter=100, regParam=0.1, elasticNetParam=0.0)\n",
        "\n",
        "# Train the model\n",
        "lr_poly_model = lr_poly.fit(train_final)\n",
        "\n",
        "# Generate predictions\n",
        "train_predictions_poly = lr_poly_model.transform(train_final)\n",
        "test_predictions_poly = lr_poly_model.transform(test_final)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_r2_poly = evaluator_r2.evaluate(train_predictions_poly)\n",
        "train_rmse_poly = evaluator_rmse.evaluate(train_predictions_poly)\n",
        "train_mae_poly = evaluator_mae.evaluate(train_predictions_poly)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_r2_poly = evaluator_r2.evaluate(test_predictions_poly)\n",
        "test_rmse_poly = evaluator_rmse.evaluate(test_predictions_poly)\n",
        "test_mae_poly = evaluator_mae.evaluate(test_predictions_poly)\n",
        "\n",
        "# Extract model parameters\n",
        "coefficients_poly = lr_poly_model.coefficients\n",
        "intercept_poly = lr_poly_model.intercept\n",
        "summary_poly = lr_poly_model.summary\n",
        "\n",
        "# Prepare polynomial feature names\n",
        "poly_feature_names = continuous_features + [\"MIN_YEARS_EXPERIENCE_SQ\"] + encoded_categorical_cols\n",
        "\n",
        "# Extract coefficient statistics\n",
        "try:\n",
        "    coef_std_errors_poly = summary_poly.coefficientStandardErrors\n",
        "    t_values_poly = summary_poly.tValues\n",
        "    p_values_poly = summary_poly.pValues\n",
        "    \n",
        "    coef_data_poly = []\n",
        "    for i, feature_name in enumerate(poly_feature_names):\n",
        "        if i < len(coefficients_poly):\n",
        "            coef = coefficients_poly[i]\n",
        "            std_err = coef_std_errors_poly[i]\n",
        "            t_val = t_values_poly[i]\n",
        "            p_val = p_values_poly[i]\n",
        "            ci_lower = coef - 1.96 * std_err\n",
        "            ci_upper = coef + 1.96 * std_err\n",
        "            \n",
        "            coef_data_poly.append({\n",
        "                'Feature': feature_name,\n",
        "                'Coefficient': coef,\n",
        "                'Std_Error': std_err,\n",
        "                'T_Value': t_val,\n",
        "                'P_Value': p_val,\n",
        "                'CI_Lower': ci_lower,\n",
        "                'CI_Upper': ci_upper\n",
        "            })\n",
        "    \n",
        "    coef_df_poly = pd.DataFrame(coef_data_poly)\n",
        "    \n",
        "    intercept_std_err_poly = coef_std_errors_poly[-1]\n",
        "    intercept_t_val_poly = t_values_poly[-1]\n",
        "    intercept_p_val_poly = p_values_poly[-1]\n",
        "    intercept_ci_lower_poly = intercept_poly - 1.96 * intercept_std_err_poly\n",
        "    intercept_ci_upper_poly = intercept_poly + 1.96 * intercept_std_err_poly\n",
        "    \n",
        "except:\n",
        "    coef_data_poly = []\n",
        "    for i, feature_name in enumerate(poly_feature_names):\n",
        "        if i < len(coefficients_poly):\n",
        "            coef = coefficients_poly[i]\n",
        "            \n",
        "            coef_data_poly.append({\n",
        "                'Feature': feature_name,\n",
        "                'Coefficient': coef,\n",
        "                'Std_Error': 'N/A',\n",
        "                'T_Value': 'N/A',\n",
        "                'P_Value': 'N/A',\n",
        "                'CI_Lower': 'N/A',\n",
        "                'CI_Upper': 'N/A'\n",
        "            })\n",
        "    \n",
        "    coef_df_poly = pd.DataFrame(coef_data_poly)\n",
        "    \n",
        "    intercept_std_err_poly = 'N/A'\n",
        "    intercept_t_val_poly = 'N/A'\n",
        "    intercept_p_val_poly = 'N/A'\n",
        "    intercept_ci_lower_poly = 'N/A'\n",
        "    intercept_ci_upper_poly = 'N/A'\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POLYNOMIAL REGRESSION MODEL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "print(f\"Intercept: {intercept_poly:,.2f}\")\n",
        "print(f\"\\nTraining Set Performance:\")\n",
        "print(f\"  R² Score: {train_r2_poly:.4f}\")\n",
        "print(f\"  RMSE: ${train_rmse_poly:,.2f}\")\n",
        "print(f\"  MAE: ${train_mae_poly:,.2f}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"  R² Score: {test_r2_poly:.4f}\")\n",
        "print(f\"  RMSE: ${test_rmse_poly:,.2f}\")\n",
        "print(f\"  MAE: ${test_mae_poly:,.2f}\")\n",
        "\n",
        "print(\"\\n--- Feature Coefficients and Statistical Significance ---\")\n",
        "print(coef_df_poly.to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Intercept Statistics ---\")\n",
        "print(f\"Intercept: {intercept_poly:,.2f}\")\n",
        "print(f\"Std Error: {intercept_std_err_poly}\")\n",
        "print(f\"T-Value: {intercept_t_val_poly}\")\n",
        "print(f\"P-Value: {intercept_p_val_poly}\")\n",
        "print(f\"95% CI: [{intercept_ci_lower_poly}, {intercept_ci_upper_poly}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPARISON: LINEAR vs POLYNOMIAL REGRESSION\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nLinear Regression Test R²: {test_r2:.4f}\")\n",
        "print(f\"Polynomial Regression Test R²: {test_r2_poly:.4f}\")\n",
        "print(f\"Improvement in R²: {test_r2_poly - test_r2:.4f}\")\n",
        "\n",
        "print(f\"\\nLinear Regression Test RMSE: ${test_rmse:,.2f}\")\n",
        "print(f\"Polynomial Regression Test RMSE: ${test_rmse_poly:,.2f}\")\n",
        "print(f\"Change in RMSE: ${test_rmse_poly - test_rmse:,.2f}\")\n",
        "\n",
        "print(f\"\\nLinear Regression Test MAE: ${test_mae:,.2f}\")\n",
        "print(f\"Polynomial Regression Test MAE: ${test_mae_poly:,.2f}\")\n",
        "print(f\"Change in MAE: ${test_mae_poly - test_mae:,.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INTERPRETATION OF POLYNOMIAL REGRESSION RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. MODEL PERFORMANCE INTERPRETATION:\")\n",
        "print(f\"   - R² Score ({test_r2_poly:.4f}): The polynomial model explains {test_r2_poly*100:.2f}% of\")\n",
        "print(\"     the variance in SALARY, compared to {:.2f}% for the linear model.\".format(test_r2*100))\n",
        "if test_r2_poly > test_r2:\n",
        "    print(f\"     * IMPROVEMENT: The polynomial model captures {(test_r2_poly - test_r2)*100:.2f}% more variance.\")\n",
        "    print(\"     * This suggests non-linear relationships exist in the data.\")\n",
        "else:\n",
        "    print(\"     * The polynomial model does not improve over the linear model.\")\n",
        "    print(\"     * This suggests the relationship may be primarily linear.\")\n",
        "\n",
        "print(f\"\\n   - RMSE (${test_rmse_poly:,.2f}): Average prediction error for polynomial model.\")\n",
        "if test_rmse_poly < test_rmse:\n",
        "    print(f\"     * IMPROVEMENT: ${test_rmse - test_rmse_poly:,.2f} reduction in RMSE.\")\n",
        "    print(\"     * The polynomial model makes more accurate predictions.\")\n",
        "else:\n",
        "    print(f\"     * The polynomial model has higher RMSE by ${test_rmse_poly - test_rmse:,.2f}.\")\n",
        "    print(\"     * This may indicate overfitting or that polynomial terms don't help.\")\n",
        "\n",
        "print(f\"\\n   - MAE (${test_mae_poly:,.2f}): Average absolute error for polynomial model.\")\n",
        "if test_mae_poly < test_mae:\n",
        "    print(f\"     * IMPROVEMENT: ${test_mae - test_mae_poly:,.2f} reduction in MAE.\")\n",
        "else:\n",
        "    print(f\"     * The polynomial model has higher MAE by ${test_mae_poly - test_mae:,.2f}.\")\n",
        "\n",
        "if train_r2_poly - test_r2_poly > 0.1:\n",
        "    print(f\"\\n   - OVERFITTING WARNING: Training R² ({train_r2_poly:.4f}) is significantly\")\n",
        "    print(f\"     higher than test R² ({test_r2_poly:.4f}).\")\n",
        "    print(\"     * The model may have learned training data patterns that don't generalize.\")\n",
        "    print(\"     * Consider reducing model complexity or increasing regularization.\")\n",
        "else:\n",
        "    print(f\"\\n   - GOOD GENERALIZATION: Training R² ({train_r2_poly:.4f}) and test R²\")\n",
        "    print(f\"     ({test_r2_poly:.4f}) are similar, indicating the model generalizes well.\")\n",
        "\n",
        "print(\"\\n2. POLYNOMIAL FEATURE INTERPRETATION:\")\n",
        "print(\"   - MIN_YEARS_EXPERIENCE_SQ: This squared term captures non-linear relationships\")\n",
        "print(\"     between experience and salary.\")\n",
        "print(\"     * Positive coefficient: Salary increases at an accelerating rate with experience\")\n",
        "print(\"       (e.g., senior positions command exponentially higher salaries)\")\n",
        "print(\"     * Negative coefficient: Salary increases at a decelerating rate with experience\")\n",
        "print(\"       (e.g., diminishing returns to additional years of experience)\")\n",
        "print(\"     * The combination of MIN_YEARS_EXPERIENCE and MIN_YEARS_EXPERIENCE_SQ allows\")\n",
        "print(\"       the model to fit a parabolic (curved) relationship.\")\n",
        "\n",
        "print(\"\\n3. MODEL SELECTION RECOMMENDATION:\")\n",
        "if test_r2_poly > test_r2 and test_rmse_poly < test_rmse:\n",
        "    print(\"   - The polynomial model outperforms the linear model on both R² and RMSE.\")\n",
        "    print(\"   - RECOMMENDATION: Use the polynomial model for predictions.\")\n",
        "elif test_r2_poly > test_r2 + 0.01:\n",
        "    print(\"   - The polynomial model shows modest improvement in R².\")\n",
        "    print(\"   - RECOMMENDATION: Consider the polynomial model if interpretability isn't critical.\")\n",
        "else:\n",
        "    print(\"   - The polynomial model does not substantially improve performance.\")\n",
        "    print(\"   - RECOMMENDATION: Prefer the simpler linear model (Occam's Razor).\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "# Show sample predictions\n",
        "test_predictions_poly.select(\"SALARY\", \"prediction\", \"features_poly\").show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize Random Forest model\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"SALARY\",\n",
        "    numTrees=200,\n",
        "    maxDepth=7,\n",
        "    seed=42,\n",
        "    maxBins=32\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "rf_model = rf.fit(train_final)\n",
        "\n",
        "# Generate predictions\n",
        "train_predictions_rf = rf_model.transform(train_final)\n",
        "test_predictions_rf = rf_model.transform(test_final)\n",
        "\n",
        "# Evaluate on training set\n",
        "train_r2_rf = evaluator_r2.evaluate(train_predictions_rf)\n",
        "train_rmse_rf = evaluator_rmse.evaluate(train_predictions_rf)\n",
        "train_mae_rf = evaluator_mae.evaluate(train_predictions_rf)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_r2_rf = evaluator_r2.evaluate(test_predictions_rf)\n",
        "test_rmse_rf = evaluator_rmse.evaluate(test_predictions_rf)\n",
        "test_mae_rf = evaluator_mae.evaluate(test_predictions_rf)\n",
        "\n",
        "# Extract feature importances\n",
        "feature_importances = rf_model.featureImportances\n",
        "feature_importance_list = [(feature_names[i], float(feature_importances[i])) \n",
        "                           for i in range(len(feature_names))]\n",
        "feature_importance_df = pd.DataFrame(feature_importance_list, \n",
        "                                     columns=['Feature', 'Importance'])\n",
        "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"RANDOM FOREST REGRESSOR MODEL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n--- Model Hyperparameters ---\")\n",
        "print(f\"Number of Trees: {rf.getNumTrees()}\")\n",
        "print(f\"Max Depth: {rf.getMaxDepth()}\")\n",
        "print(f\"Max Bins: {rf.getMaxBins()}\")\n",
        "print(f\"Seed: {rf.getSeed()}\")\n",
        "\n",
        "print(\"\\n--- Model Performance Metrics ---\")\n",
        "print(f\"\\nTraining Set Performance:\")\n",
        "print(f\"  R² Score: {train_r2_rf:.4f}\")\n",
        "print(f\"  RMSE: ${train_rmse_rf:,.2f}\")\n",
        "print(f\"  MAE: ${train_mae_rf:,.2f}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"  R² Score: {test_r2_rf:.4f}\")\n",
        "print(f\"  RMSE: ${test_rmse_rf:,.2f}\")\n",
        "print(f\"  MAE: ${test_mae_rf:,.2f}\")\n",
        "\n",
        "print(\"\\n--- Feature Importances ---\")\n",
        "print(feature_importance_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INTERPRETATION OF RANDOM FOREST RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. HYPERPARAMETER SELECTION:\")\n",
        "print(f\"   - Number of Trees: {rf.getNumTrees()}\")\n",
        "print(\"     * More trees generally improve performance but increase training time\")\n",
        "print(\"     * Random Forest averages predictions across all trees, reducing variance\")\n",
        "print(f\"\\n   - Max Depth: {rf.getMaxDepth()}\")\n",
        "print(\"     * Controls how deep each tree can grow\")\n",
        "print(\"     * Deeper trees = more complex patterns but higher overfitting risk\")\n",
        "print(\"     * Shallower trees = simpler patterns but may underfit\")\n",
        "\n",
        "print(\"\\n2. MODEL PERFORMANCE:\")\n",
        "if test_r2_rf > test_r2 and test_r2_rf > test_r2_poly:\n",
        "    print(\"     * BEST PERFORMER: Outperforms both linear and polynomial models\")\n",
        "elif test_r2_rf > test_r2:\n",
        "    print(\"     * Outperforms linear regression\")\n",
        "else:\n",
        "    print(\"     * Does not improve over simpler models\")\n",
        "\n",
        "overfitting_gap = train_r2_rf - test_r2_rf\n",
        "if overfitting_gap > 0.15:\n",
        "    print(f\"\\n   - OVERFITTING WARNING: Training R² ({train_r2_rf:.4f}) is {overfitting_gap:.4f}\")\n",
        "    print(f\"     higher than test R² ({test_r2_rf:.4f})\")\n",
        "elif overfitting_gap > 0.05:\n",
        "    print(f\"\\n   - MINOR OVERFITTING: Training R² ({train_r2_rf:.4f}) is slightly higher\")\n",
        "    print(f\"     than test R² ({test_r2_rf:.4f})\")\n",
        "else:\n",
        "    print(f\"\\n   - EXCELLENT GENERALIZATION: Training and test R² are very similar\")\n",
        "\n",
        "print(\"\\n3. FEATURE IMPORTANCE:\")\n",
        "top_5_features = feature_importance_df.head(5)\n",
        "print(f\"\\n   Top 5 Most Important Features:\")\n",
        "for idx, row in top_5_features.iterrows():\n",
        "    print(f\"     {idx+1}. {row['Feature']}: {row['Importance']:.4f} ({row['Importance']*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "# Show sample predictions\n",
        "test_predictions_rf.select(\"SALARY\", \"prediction\", \"features\").show(10, truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Importance Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create feature importance plot\n",
        "top_10_importance = feature_importance_df.head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(data=top_10_importance, y='Feature', x='Importance', palette='viridis')\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.title('Top 10 Most Important Features - Random Forest Model', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Feature Importance Interpretation ---\")\n",
        "print(\"Random Forest feature importances measure the total reduction in prediction\")\n",
        "print(\"error contributed by each feature across all trees in the ensemble.\")\n",
        "\n",
        "total_importance_top10 = top_10_importance['Importance'].sum()\n",
        "print(f\"\\n- Top 10 features account for {total_importance_top10*100:.1f}% of total importance\")\n",
        "\n",
        "total_importance_top5 = feature_importance_df.head(5)['Importance'].sum()\n",
        "print(f\"- Top 5 features account for {total_importance_top5*100:.1f}% of total importance\")\n",
        "\n",
        "if feature_importance_df.iloc[0]['Importance'] > 0.4:\n",
        "    print(f\"\\nWARNING: {feature_importance_df.iloc[0]['Feature']} dominates with\")\n",
        "    print(f\"{feature_importance_df.iloc[0]['Importance']*100:.1f}% importance!\")\n",
        "    print(\"This strongly suggests data leakage.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compare 3 Models – GLR, Polynomial, RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Function to calculate log-likelihood and BIC\n",
        "def calculate_log_likelihood_and_bic(predictions, n_params):\n",
        "    predictions_pd = predictions.select(\"SALARY\", \"prediction\").toPandas()\n",
        "    residuals = predictions_pd[\"SALARY\"] - predictions_pd[\"prediction\"]\n",
        "    rss = (residuals ** 2).sum()\n",
        "    \n",
        "    dispersion = rss / (len(predictions_pd) - n_params)\n",
        "    n = len(predictions_pd)\n",
        "    \n",
        "    log_likelihood = -0.5 * (n * math.log(2 * math.pi) + n * math.log(dispersion) + rss / dispersion)\n",
        "    bic = n_params * math.log(n) - 2 * log_likelihood\n",
        "    \n",
        "    return log_likelihood, bic\n",
        "\n",
        "# Calculate number of parameters for each model\n",
        "n_features_linear = len(feature_names)\n",
        "n_params_linear = n_features_linear + 1\n",
        "\n",
        "n_features_poly = len(poly_feature_names)\n",
        "n_params_poly = n_features_poly + 1\n",
        "\n",
        "n_params_rf = n_features_linear + 1\n",
        "\n",
        "# Calculate log-likelihood and BIC for each model\n",
        "log_likelihood_linear, bic_linear = calculate_log_likelihood_and_bic(test_predictions, n_params_linear)\n",
        "log_likelihood_poly, bic_poly = calculate_log_likelihood_and_bic(test_predictions_poly, n_params_poly)\n",
        "log_likelihood_rf, bic_rf = calculate_log_likelihood_and_bic(test_predictions_rf, n_params_rf)\n",
        "\n",
        "# Calculate AIC\n",
        "try:\n",
        "    aic_linear = summary.aic\n",
        "except:\n",
        "    aic_linear = 2 * n_params_linear - 2 * log_likelihood_linear\n",
        "\n",
        "try:\n",
        "    aic_poly = summary_poly.aic\n",
        "except:\n",
        "    aic_poly = 2 * n_params_poly - 2 * log_likelihood_poly\n",
        "\n",
        "aic_rf = 2 * n_params_rf - 2 * log_likelihood_rf\n",
        "\n",
        "# Create comprehensive comparison dataframe\n",
        "comparison_metrics = {\n",
        "    'Model': ['Linear Regression', 'Polynomial Regression', 'Random Forest'],\n",
        "    'Test_R2': [test_r2, test_r2_poly, test_r2_rf],\n",
        "    'Test_RMSE': [test_rmse, test_rmse_poly, test_rmse_rf],\n",
        "    'Test_MAE': [test_mae, test_mae_poly, test_mae_rf],\n",
        "    'Train_R2': [train_r2, train_r2_poly, train_r2_rf],\n",
        "    'Overfitting_Gap': [train_r2 - test_r2, train_r2_poly - test_r2_poly, train_r2_rf - test_r2_rf],\n",
        "    'AIC': [aic_linear, aic_poly, aic_rf],\n",
        "    'BIC': [bic_linear, bic_poly, bic_rf],\n",
        "    'Log_Likelihood': [log_likelihood_linear, log_likelihood_poly, log_likelihood_rf],\n",
        "    'Num_Parameters': [n_params_linear, n_params_poly, n_params_rf]\n",
        "}\n",
        "comparison_df = pd.DataFrame(comparison_metrics)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\n\" + comparison_df.to_string(index=False))\n",
        "\n",
        "# Identify best performers\n",
        "best_r2_idx = comparison_df['Test_R2'].idxmax()\n",
        "best_rmse_idx = comparison_df['Test_RMSE'].idxmin()\n",
        "best_mae_idx = comparison_df['Test_MAE'].idxmin()\n",
        "best_aic_idx = comparison_df['AIC'].idxmin()\n",
        "best_bic_idx = comparison_df['BIC'].idxmin()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BEST PERFORMERS BY METRIC\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nBest R² Score: {comparison_df.iloc[best_r2_idx]['Model']} ({comparison_df.iloc[best_r2_idx]['Test_R2']:.4f})\")\n",
        "print(f\"Best RMSE: {comparison_df.iloc[best_rmse_idx]['Model']} (${comparison_df.iloc[best_rmse_idx]['Test_RMSE']:,.2f})\")\n",
        "print(f\"Best MAE: {comparison_df.iloc[best_mae_idx]['Model']} (${comparison_df.iloc[best_mae_idx]['Test_MAE']:,.2f})\")\n",
        "print(f\"Best AIC: {comparison_df.iloc[best_aic_idx]['Model']} ({comparison_df.iloc[best_aic_idx]['AIC']:,.2f})\")\n",
        "print(f\"Best BIC: {comparison_df.iloc[best_bic_idx]['Model']} ({comparison_df.iloc[best_bic_idx]['BIC']:,.2f})\")\n",
        "\n",
        "# Create predictions comparison dataframe\n",
        "test_predictions_pd = test_predictions.select(\"SALARY\", \"prediction\").toPandas()\n",
        "test_predictions_pd.columns = [\"Actual\", \"Linear_Predicted\"]\n",
        "\n",
        "test_predictions_poly_pd = test_predictions_poly.select(\"SALARY\", \"prediction\").toPandas()\n",
        "test_predictions_poly_pd.columns = [\"Actual_Poly\", \"Polynomial_Predicted\"]\n",
        "\n",
        "test_predictions_rf_pd = test_predictions_rf.select(\"SALARY\", \"prediction\").toPandas()\n",
        "test_predictions_rf_pd.columns = [\"Actual_RF\", \"RF_Predicted\"]\n",
        "\n",
        "predictions_df = pd.concat([\n",
        "    test_predictions_pd,\n",
        "    test_predictions_poly_pd[\"Polynomial_Predicted\"],\n",
        "    test_predictions_rf_pd[\"RF_Predicted\"]\n",
        "], axis=1)\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "fig.suptitle('Actual vs Predicted Salary - Model Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Linear Regression plot\n",
        "sns.scatterplot(data=predictions_df, x=\"Actual\", y=\"Linear_Predicted\", alpha=0.6, ax=axes[0, 0])\n",
        "axes[0, 0].plot([predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                [predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0, 0].set_title(f'Linear Regression\\nR²={test_r2:.4f}, RMSE=${test_rmse:,.0f}')\n",
        "axes[0, 0].set_xlabel('Actual Salary ($)')\n",
        "axes[0, 0].set_ylabel('Predicted Salary ($)')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Polynomial Regression plot\n",
        "sns.scatterplot(data=predictions_df, x=\"Actual\", y=\"Polynomial_Predicted\", alpha=0.6, ax=axes[0, 1], color='green')\n",
        "axes[0, 1].plot([predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                [predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0, 1].set_title(f'Polynomial Regression\\nR²={test_r2_poly:.4f}, RMSE=${test_rmse_poly:,.0f}')\n",
        "axes[0, 1].set_xlabel('Actual Salary ($)')\n",
        "axes[0, 1].set_ylabel('Predicted Salary ($)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Random Forest plot\n",
        "sns.scatterplot(data=predictions_df, x=\"Actual\", y=\"RF_Predicted\", alpha=0.6, ax=axes[1, 0], color='orange')\n",
        "axes[1, 0].plot([predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                [predictions_df[\"Actual\"].min(), predictions_df[\"Actual\"].max()],\n",
        "                'r--', lw=2, label='Perfect Prediction')\n",
        "axes[1, 0].set_title(f'Random Forest\\nR²={test_r2_rf:.4f}, RMSE=${test_rmse_rf:,.0f}')\n",
        "axes[1, 0].set_xlabel('Actual Salary ($)')\n",
        "axes[1, 0].set_ylabel('Predicted Salary ($)')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Residuals distribution\n",
        "residuals_data = pd.DataFrame({\n",
        "    'Linear': predictions_df[\"Actual\"] - predictions_df[\"Linear_Predicted\"],\n",
        "    'Polynomial': predictions_df[\"Actual\"] - predictions_df[\"Polynomial_Predicted\"],\n",
        "    'Random Forest': predictions_df[\"Actual\"] - predictions_df[\"RF_Predicted\"]\n",
        "})\n",
        "\n",
        "residuals_melted = residuals_data.melt(var_name='Model', value_name='Residual')\n",
        "sns.boxplot(data=residuals_melted, x='Model', y='Residual', ax=axes[1, 1])\n",
        "axes[1, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "axes[1, 1].set_title('Residuals Distribution by Model')\n",
        "axes[1, 1].set_xlabel('Model')\n",
        "axes[1, 1].set_ylabel('Residual (Actual - Predicted)')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"INTERPRETATION OF MODEL COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n1. INFORMATION CRITERIA INTERPRETATION:\")\n",
        "print(\"   - AIC (Akaike Information Criterion):\")\n",
        "print(\"     * Measures model quality balancing fit and complexity\")\n",
        "print(\"     * LOWER is better - penalizes adding unnecessary parameters\")\n",
        "print(\"     * Best for prediction-focused model selection\")\n",
        "\n",
        "print(\"\\n   - BIC (Bayesian Information Criterion):\")\n",
        "print(\"     * Similar to AIC but penalizes complexity more strongly\")\n",
        "print(\"     * LOWER is better - stronger penalty for model complexity\")\n",
        "print(\"     * Best for identifying the 'true' model structure\")\n",
        "\n",
        "print(\"\\n2. FINAL RECOMMENDATION:\")\n",
        "votes = {'Linear Regression': 0, 'Polynomial Regression': 0, 'Random Forest': 0}\n",
        "votes[comparison_df.iloc[best_r2_idx]['Model']] += 1\n",
        "votes[comparison_df.iloc[best_rmse_idx]['Model']] += 1\n",
        "votes[comparison_df.iloc[best_aic_idx]['Model']] += 1\n",
        "votes[comparison_df.iloc[best_bic_idx]['Model']] += 1\n",
        "\n",
        "winner = max(votes, key=votes.get)\n",
        "print(f\"   Based on R², RMSE, AIC, and BIC: {winner} wins {votes[winner]}/4 metrics\")\n",
        "\n",
        "if winner == 'Linear Regression':\n",
        "    print(\"\\n   RECOMMENDATION: Use Linear Regression\")\n",
        "    print(\"   - Simplest model with competitive performance\")\n",
        "    print(\"   - Most interpretable coefficients\")\n",
        "elif winner == 'Polynomial Regression':\n",
        "    print(\"\\n   RECOMMENDATION: Use Polynomial Regression\")\n",
        "    print(\"   - Captures non-linear relationships\")\n",
        "    print(\"   - Still interpretable\")\n",
        "else:\n",
        "    print(\"\\n   RECOMMENDATION: Use Random Forest\")\n",
        "    print(\"   - Best predictive performance\")\n",
        "    print(\"   - Handles complex non-linear patterns\")\n",
        "\n",
        "print(\"\\n   IMPORTANT: All models suffer from data leakage (SALARY_FROM/SALARY_TO)\")\n",
        "print(\"   Remove these features and retrain for realistic production deployment\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}